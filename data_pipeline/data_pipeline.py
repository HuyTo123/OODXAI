import os
import sys
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision import models
import numpy as np
import cv2
import shap
from PIL import Image
from skimage.segmentation import slic
from tqdm.autonotebook import tqdm
from pathlib import Path

# ==============================================================================
# 1. KHAI BÃO VÃ€ Cáº¤U HÃŒNH TRUNG TÃ‚M
# ==============================================================================
print("--- KHá»I Táº O Cáº¤U HÃŒNH ---")

# --- Cáº¤U HÃŒNH VÃ’NG Láº¶P (NgÆ°á»i dÃ¹ng tÃ¹y chá»‰nh) ---
START_INDEX = 50     # Báº¯t Ä‘áº§u tá»« Cat_50
END_INDEX = 52      # Káº¿t thÃºc á»Ÿ Cat_100
BASE_IMAGE_DIR = "testmodel/cat_dogs_huggingface/Cat_and_Dog_Images/test/Cat/"
PREFIX_NAME = "Cat_" # Tiá»n tá»‘ tÃªn file
EXTENSION = ".png"   # ÄuÃ´i file

# --- Cáº¥u hÃ¬nh tham sá»‘ khÃ¡c ---
TOP_K = 3
MODEL_PATH = 'testmodel/cat_dogs_huggingface/cat_dog_resnet50_best.pth'
NUM_SUPERPIXELS = 50
NUM_SAMPLES = 500 
NUM_RUNS = 50 

TRANSFORM_MEAN = [0.485, 0.456, 0.406]
TRANSFORM_STD = [0.229, 0.224, 0.225]
CLASS_NAMES = ['Cat', 'Dog']

# ThÆ° má»¥c output
OUTPUT_DIR_ORIGINAL = "testmodel/cat_dogs_huggingface/CatandDog_segment"
OUTPUT_DIR_NOISE_IMG = "testmodel/cat_dogs_huggingface/CatandDog_segment_noise"
OUTPUT_DIR_NOISE_ANALYSIS = "testmodel/cat_dogs_huggingface/CatandDog_segment_with_noise"

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Sá»­ dá»¥ng thiáº¿t bá»‹: {DEVICE}")


# ==============================================================================
# 2. CÃC HÃ€M TIá»†N ÃCH
# ==============================================================================

def load_model(num_classes, device):
    """Táº£i kiáº¿n trÃºc model ResNet50 vÃ  load trá»ng sá»‘ Ä‘Ã£ huáº¥n luyá»‡n."""
    model = models.resnet50(weights=None)
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, num_classes)
    
    if not os.path.exists(MODEL_PATH):
        print(f"Lá»–I: KhÃ´ng tÃ¬m tháº¥y model táº¡i: {MODEL_PATH}")
        sys.exit()
        
    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
    model = model.to(device)
    model.eval()
    return model

def run_shap_analysis(model, current_image_path, top_k, output_base_dir, analysis_type='original'):
    """
    HÃ m lÃµi: thá»±c hiá»‡n phÃ¢n tÃ­ch SHAP trÃªn má»™t áº£nh, lÆ°u káº¿t quáº£ vÃ  tráº£ vá» cÃ¡c thÃ´ng tin cáº§n thiáº¿t.
    """
    # --- A. Chuáº©n bá»‹ áº£nh vÃ  phÃ¢n Ä‘oáº¡n Superpixel ---
    transform_for_slic = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])
    
    image = cv2.imread(current_image_path)
    if image is None:
        print(f"Lá»–I: KhÃ´ng Ä‘á»c Ä‘Æ°á»£c áº£nh táº¡i: {current_image_path}")
        return None, None, None

    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    pil_image = Image.fromarray(image_rgb)

    image_tensor_unnormalized = transform_for_slic(pil_image)
    image_numpy_unnormalized = image_tensor_unnormalized.permute(1, 2, 0).numpy()
    segments_slic = slic(image_numpy_unnormalized, n_segments=NUM_SUPERPIXELS,
                         compactness=10, sigma=1, start_label=0)
    num_actual_superpixels = len(np.unique(segments_slic))
    print(f"PhÃ¢n vÃ¹ng áº£nh thÃ nh {num_actual_superpixels} siÃªu pixel.")

    # --- B. Äá»‹nh nghÄ©a hÃ m dá»± Ä‘oÃ¡n cho SHAP ---
    transform_for_prediction = transforms.Compose([
        transforms.ToTensor(),
        transforms.Resize((224, 224)),
        transforms.Normalize(TRANSFORM_MEAN, TRANSFORM_STD)
    ])
    background_color = image_numpy_unnormalized.mean((0, 1))

    def prediction_function(z):
        batch_size = 10
        all_logits = []
        unique_labels = np.unique(segments_slic)
        for i in range(0, z.shape[0], batch_size):
            z_batch = z[i:i + batch_size]
            masked_images_np = []
            for mask in z_batch:
                temp_image = image_numpy_unnormalized.copy()
                inactive_segments = np.where(mask == 0)[0]
                inactive_labels = unique_labels[inactive_segments]
                mask_all_inactive = np.isin(segments_slic, inactive_labels)
                temp_image[mask_all_inactive] = background_color
                masked_images_np.append(temp_image)
            tensors = torch.stack([transform_for_prediction(img) for img in masked_images_np]).to(DEVICE)
            with torch.no_grad():
                logits = model(tensors)
            all_logits.append(logits.cpu().numpy())
        return np.concatenate(all_logits, axis=0)

    # --- C. Cháº¡y vÃ²ng láº·p thá»‘ng kÃª SHAP ---
    print(f"Báº¯t Ä‘áº§u cháº¡y {NUM_RUNS} láº§n KernelSHAP Ä‘á»ƒ láº¥y sá»‘ liá»‡u thá»‘ng kÃª...")
    positive_counts = np.zeros(num_actual_superpixels)
    negative_counts = np.zeros(num_actual_superpixels)
    shap_value_sums = np.zeros((num_actual_superpixels, len(CLASS_NAMES)))

    with torch.no_grad():
        logits = model(transform_for_prediction(pil_image).unsqueeze(0).to(DEVICE))
        predicted_class = torch.argmax(logits, dim=1).item()
    
    explainer = shap.KernelExplainer(prediction_function, np.zeros((1, num_actual_superpixels)))

    # DÃ¹ng tqdm vá»›i tham sá»‘ leave=False Ä‘á»ƒ khÃ´ng in quÃ¡ nhiá»u dÃ²ng khi cháº¡y nhiá»u áº£nh
    for _ in tqdm(range(NUM_RUNS), desc="Cháº¡y thá»‘ng kÃª SHAP", leave=False):
        shap_values = explainer.shap_values(np.ones((1, num_actual_superpixels)), nsamples=NUM_SAMPLES, silent=True)
        shap_values_for_this_run = np.array(shap_values)[0, :, :]
        shap_values_for_predicted_class = shap_values_for_this_run[:, predicted_class]

        # TÃ¬m cÃ¡c segment cÃ³ giÃ¡ trá»‹ dÆ°Æ¡ng vÃ  Ã¢m
        positive_indices = np.where(shap_values_for_predicted_class > 0)[0]
        negative_indices = np.where(shap_values_for_predicted_class < 0)[0]
        
        # Cáº­p nháº­t bá»™ Ä‘áº¿m
        positive_counts[positive_indices] += 1
        negative_counts[negative_indices] += 1
        
        # Cá»™ng dá»“n SHAP values vÃ o tá»•ng
        shap_value_sums += shap_values_for_this_run

    # --- D. TÃ­nh toÃ¡n vÃ  xÃ¡c Ä‘á»‹nh Top K ---
    positive_prob = positive_counts / NUM_RUNS
    negative_prob = negative_counts / NUM_RUNS
    mean_shap_values = shap_value_sums / NUM_RUNS
    
    shap_values_for_pred_class = mean_shap_values[:, predicted_class]
    sorted_indices = np.argsort(shap_values_for_pred_class)[::-1]
    top_k_segment_ids = sorted_indices[:top_k]

    # --- E. LÆ°u káº¿t quáº£ ra file text (GIá»® NGUYÃŠN FORMAT Cá»¦A Báº N) ---
    class_folder = os.path.basename(os.path.dirname(current_image_path))
    file_name_without_ext = Path(current_image_path).stem
    if analysis_type == 'noise':
        file_name_without_ext += '_top_k_noise'
    final_output_dir = os.path.join(output_base_dir, class_folder)
    os.makedirs(final_output_dir, exist_ok=True)
    
    output_file_path_full = os.path.join(final_output_dir, f"{file_name_without_ext}.txt")
    output_file_path_final = os.path.join(final_output_dir, f"{file_name_without_ext}_final.txt")

    print(f"\nÄang lÆ°u káº¿t quáº£ vÃ o thÆ° má»¥c: {final_output_dir}")
    
    # === KHÃ”I PHá»¤C FORMAT GHI FILE Cá»¦A Báº N ===
    with open(output_file_path_full, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write(f"Káº¾T QUáº¢ THá»NG KÃŠ SHAP\n")
        f.write(f"File áº£nh: {current_image_path}\n")
        all_scores = logits.cpu().numpy()[0]
        scores_str = ", ".join([f"{s:.4f}" for s in all_scores])
        f.write(f"Dá»± Ä‘oÃ¡n: class {predicted_class} - Logit Scores: [{scores_str}]\n")
        f.write(f"Top {top_k} Segment quan trá»ng: {', '.join(map(str, top_k_segment_ids))}\n")
        f.write("="*80 + "\n")
        f.write(f"{'Segment ID':<12} | {'P(TÃ­ch cá»±c)':<15} | {'P(TiÃªu cá»±c)':<15} | {'Mean SHAP (Class 0)':<20} | {'Mean SHAP (Class 1)':<20}\n")
        f.write("-"*80 + "\n")
        for i in range(num_actual_superpixels):
            f.write(f"{i:<12} | {positive_prob[i]:<15.2%} | {negative_prob[i]:<15.2%} | {mean_shap_values[i, 0]:<20.4f} | {mean_shap_values[i, 1]:<20.4f}\n")
    
    with open(output_file_path_final, 'w', encoding='utf-8') as f:
        for i in sorted_indices[:5]:
            f.write(f"{i} {positive_prob[i]:.4f} {negative_prob[i]:.4f} {mean_shap_values[i, 0]:.4f} {mean_shap_values[i, 1]:.4f}\n")
    # ============================================

    print("LÆ°u file thÃ nh cÃ´ng!")
    return top_k_segment_ids, image_numpy_unnormalized, segments_slic


def create_and_save_noised_image(original_image_numpy, original_segments, labels_to_black, original_image_path, output_dir):
    """Táº¡o áº£nh nhiá»…u báº±ng cÃ¡ch bÃ´i Ä‘en cÃ¡c superpixel Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh vÃ  lÆ°u láº¡i."""
    
    # --- Táº¡o báº£n sao áº£nh Ä‘á»ƒ chá»‰nh sá»­a ---
    output_image = original_image_numpy.copy()

    # --- Láº·p qua danh sÃ¡ch ID vÃ  bÃ´i Ä‘en ---
    for label in labels_to_black:
        mask = original_segments == label
        output_image[mask] = [0, 0, 0] # MÃ u Ä‘en

    # --- XÃ¢y dá»±ng Ä‘Æ°á»ng dáº«n vÃ  lÆ°u file ---
    input_path = Path(original_image_path)
    class_name = input_path.parts[-2]
    filename = input_path.name
    
    output_class_dir = Path(output_dir) / class_name
    output_class_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_class_dir / filename
    
    # Chuyá»ƒn Ä‘á»•i vá» Ä‘á»‹nh dáº¡ng áº£nh 8-bit vÃ  lÆ°u
    image_to_save_uint8 = (output_image * 255).astype(np.uint8)
    pil_image_to_save = Image.fromarray(image_to_save_uint8)
    pil_image_to_save.save(output_path)
    
    print(f"áº¢nh nhiá»…u Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {output_path}")
    return str(output_path)


def process_single_image(model, image_path, image_index):
    """HÃ m Ä‘iá»u phá»‘i quy trÃ¬nh cho 1 áº£nh"""
    print(f"\n" + "#"*60)
    print(f" ÄANG Xá»¬ LÃ áº¢NH THá»¨ {image_index}: {os.path.basename(image_path)}")
    print(f"#"*60)

    # --- BÆ°á»›c 1: PhÃ¢n tÃ­ch áº£nh gá»‘c ---
    print(f"-> [áº¢nh {image_index}] BÆ°á»›c 1: PhÃ¢n tÃ­ch áº£nh gá»‘c")
    top_k_ids, original_numpy, original_segments = run_shap_analysis(
        model, image_path, TOP_K, OUTPUT_DIR_ORIGINAL
    )
    
    if top_k_ids is None:
        print(f"-> [áº¢nh {image_index}] Bá» QUA: Lá»—i khi phÃ¢n tÃ­ch áº£nh gá»‘c.")
        return

    # --- BÆ°á»›c 2: Táº¡o áº£nh nhiá»…u ---
    print(f"-> [áº¢nh {image_index}] BÆ°á»›c 2: Táº¡o áº£nh nhiá»…u")
    noised_image_path = create_and_save_noised_image(
        original_numpy, original_segments, top_k_ids, 
        image_path, OUTPUT_DIR_NOISE_IMG
    )

    # --- BÆ°á»›c 3: PhÃ¢n tÃ­ch áº£nh nhiá»…u ---
    print(f"-> [áº¢nh {image_index}] BÆ°á»›c 3: PhÃ¢n tÃ­ch áº£nh nhiá»…u")
    
    # TÃ¡ch thÆ° má»¥c output cho phÃ¢n tÃ­ch nhiá»…u Ä‘á»ƒ trÃ¡nh Ä‘Ã¨ file
    noise_file_name_stem = Path(noised_image_path).stem
    
    run_shap_analysis(
        model, noised_image_path, TOP_K, 
        OUTPUT_DIR_NOISE_ANALYSIS,
        analysis_type='noise'
    )
    print(f"-> [áº¢nh {image_index}] HOÃ€N THÃ€NH.")


# ==============================================================================
# 3. LUá»’NG THá»°C THI CHÃNH (ÄÃƒ Cáº¬P NHáº¬T VÃ’NG Láº¶P)
# ==============================================================================
if __name__ == '__main__':
    # --- BÆ°á»›c 0: Táº£i model má»™t láº§n duy nháº¥t ---
    print("Äang táº£i model...")
    model = load_model(num_classes=len(CLASS_NAMES), device=DEVICE)

    # --- VÃ²ng láº·p xá»­ lÃ½ ---
    print(f"Báº¯t Ä‘áº§u vÃ²ng láº·p tá»« {START_INDEX} Ä‘áº¿n {END_INDEX}...")
    
    for i in range(START_INDEX, END_INDEX + 1):
        # Táº¡o Ä‘Æ°á»ng dáº«n Ä‘áº§y Ä‘á»§: .../Cat/Cat_50.png
        file_name = f"{PREFIX_NAME}{i}{EXTENSION}"
        current_img_path = os.path.join(BASE_IMAGE_DIR, file_name)

        # Kiá»ƒm tra xem file cÃ³ tá»“n táº¡i khÃ´ng
        if os.path.exists(current_img_path):
            try:
                process_single_image(model, current_img_path, i)
            except Exception as e:
                print(f"Lá»–I NGOáº I Lá»† táº¡i áº£nh {file_name}: {e}")
                continue 
        else:
            # print(f"-> [Cáº£nh bÃ¡o] KhÃ´ng tÃ¬m tháº¥y file: {file_name}") # Báº­t lÃªn náº¿u cáº§n debug
            pass

    print("\n" + "="*40)
    print("ğŸ‰ ÄÃƒ CHáº Y XONG TOÃ€N Bá»˜ DANH SÃCH áº¢NH! ğŸ‰")
    print("="*40)